---
title: "Regression analysis on the safe status of Toronto apartments"
author: "Yichun Zhang,1006033187"
subtitle: STA302 Final Project
output:
  pdf_document: default
---

```{r, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
```


# Introduction

Apartment safety is an essential factor that affects people's life safety. On the one hand, apartment security affects people's living conditions and living standards. People tend to buy apartments with higher safety scores. The apartment safety score is one of the most critical indicators to help us choose an apartment. On the other hand, the value of real estate is enormous, and apartment security is directly reflected in the value of the apartment. At the same time, Toronto's apartments are mainly concentrated in densely populated areas like the city center. Since the apartment has a long service life as a residence, the safety of the apartment is likely to be affected by various factors within the service life. Due to the scattered households and asymmetry of information, ensuring the safety of apartments requires reasonable supervision by the government. The government needs to understand the specific influencing factors of apartment safety to regulate the property better, set standards, and timely supervise and punish them. In response to the issue of apartment safety, the government promulgated the apartment building standard RentSafeTo in 2017 to restrict owners and operators of apartment buildings above three floors from meeting the building maintenance standards. According to this standard, apartments must be evaluated at least once every three years. Therefore, an in-depth understanding of the factors that influence apartment security in Toronto can help the government determine the importance of different factors, thereby achieving differentiated management. The government can revise the detailed rules of apartment building evaluation standards in the future based on the size of the impact on apartment safety to more efficiently protect the safety of residents.

# Method selection

The multiple linear regression (MLR) are used to study the relations between many variables in th form: 

$$y = \beta_0 + \beta_1x_1 + ...+ \beta_px_p+ \epsilon$$
Where $\beta_i$ represents the coefficients need to estiamted, $x_i, i = 1...p$ is the predictor variables, y is the response variable, $\epsilon$ is the error term. 

The assumptions on $\epsilon$ are : 
1. $E(\epsilon) = 0$
2. $V(\epsilon) = \sigma^2I$
3. $\epsilon$ follow normal distribution. 

Under these assumptions, we can get a best linear unbiased estimate (BLUE) by the ordinary least square method. 

## Variable selection
If a dataset has p predictors, there would be $2^p$ subset of the predictors in the regression analysis. Thus, when dealing with the dataset will a number of variables, we need to resort to automated selection methods to get a preferred model. Before this procedure, we can use the partial F test to eliminate some variables if we think these variables are unrelated to the research question. There are four measures used as the criteria for selecting models, which are Adjusted $R^2$, Akaike's Information Criterion (AIC), corrected AIC and BIC. In general, we prefer to select a model with a high adjusted $R^2$ while having a small AIC, AICc and BIC. However, sometimes, different models will get by these measures. Thus, the guideline to help us select the model as the best one if it has an adjusted $R^2$ that is slightly smaller but has one of the smallest values of AIC, AICc or BIC and fewer predictors. 

Forward/backward model selection is the most popular stepwise selection method. Forward model selection begins with no predictors and adds one predictor at a time, while backward elimination begins with all the predictors and deletes one predictor at a time. The automated selection method provides us with a systematic way to select a model from a large set of predictors. However, we may not get the best model due to its one-direction operation. 

## Model validation

To validate a model, we need to select an independent dataset from the same population of train dataset and to see if this model has similar performance in the new dataset. We can split the given dataset into two parts: train and test dataset. The proportion to split the dataset can be arbitrary, and 50/50 is the most common split proportion. 

Sometimes we cannot validate our model. Possible reasons for not validating the model include: 1) test dataset is different from training dataset; 2) too many influential points 3) small size of test dataset; 4) specific transformation to correct the model assumption. Thus, we need to compare the distribution of variables in  test dataset before the model validation procedure.

## Model violation and diagnostics  

When variable selecting procedure, we need to test the assumptions every times we change the model. However, it will take too much time. Instead, we can assess assumptions with EDA or Residual plots for the full model and the final model sometimes. For example, the histogram of the response variable in EDA can be used to assess the normality assumption. The scatter plot can help us identify the nonlinearity between variables and potential multicollinearity. Residual plots are the most common way to assess violation. Any patterns in the residual plot may suggest some assumption violation of this model. If the non-constant variance, non-linearity and non-normality assumption violate, we can use the transformation method to fix these assumptions. 

# Result

## Description of Data

The dataset has 9688 observations and 40 variables, within which some variables record the score for each area. I want to estimate the overall rating of the apartments. Thus, I dropped these variables, and kept 9636 observations and eight variables. I split the dataset randomly by 50/50 to the train and test dataset.  Their summaries are shown in Table 1. The average built year is 1961, and the mean evaluated age is around 60 years. Due to the old age of these buildings, safety issue becomes more crucial. We can find that the train and test dataset have the similar distribution so that we can validate our final model by the test dataset. The pairwise scatter plots are shown in Figure 1, and no apparent nonlinear trend between score and other predictors appears in the figures. There is no very high correlation between covariates for these predictors, so there is no obvious multicollinearity problem. 


```{r, include = FALSE}
library(opendatatoronto)
library(dplyr)

# get package
package <- show_package("4ef82789-e038-44ef-a478-a8f3590c3eb1")
package

# get all resources for this package
resources <- list_package_resources("4ef82789-e038-44ef-a478-a8f3590c3eb1")

# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))

# load the first datastore resource as a sample
data <- filter(datastore_resources, row_number()==1) %>% get_resource()
data
# Here you can load in and clean the data (you may need to do the cleaning in a separate R script). 

# You may need additional chunks, in case you want to include some of the cleaning output.

# Notice that the include=FALSE means that the code, and its resulting output, in this chunk will not appear in the pdf.
rent = data%>%mutate(id = c(1:nrow(data)),YEAR_BUILT = as.numeric(YEAR_BUILT),YEAR_EVALUATED = as.numeric(YEAR_EVALUATED), CONFIRMED_STOREYS = as.numeric(CONFIRMED_STOREYS),CONFIRMED_UNITS = as.numeric(CONFIRMED_UNITS),SCORE = as.numeric(SCORE),NO_OF_AREAS_EVALUATED = as.numeric(NO_OF_AREAS_EVALUATED),LATITUDE = as.numeric(LATITUDE),LONGITUDE = as.numeric(LONGITUDE),)%>%dplyr::select(id,YEAR_BUILT,YEAR_EVALUATED,PROPERTY_TYPE,CONFIRMED_STOREYS,CONFIRMED_UNITS,SCORE,NO_OF_AREAS_EVALUATED, LATITUDE,LONGITUDE)%>% mutate(Age_Evaluated = YEAR_EVALUATED - YEAR_BUILT)%>% na.omit()

## Create training and test set ##
set.seed(1)
n = nrow(rent)
train <- rent[sample(seq_len(n), size = round(n/2)),]
test <- rent[!rent$id %in% train$id,]
nrow(test)
nrow(train)
```

```{r, include = FALSE}
rent = train
summary(rent)
table(rent$PROPERTY_TYPE)
table(rent$PROPERTY_TYPE)/length(rent$PROPERTY_TYPE)

sd(rent$YEAR_BUILT)
sd(rent$YEAR_EVALUATED)
sd(rent$CONFIRMED_STOREYS)
sd(rent$CONFIRMED_UNITS)
sd(rent$SCORE)
sd(rent$NO_OF_AREAS_EVALUATED)
sd(rent$Age_Evaluated)
sd(rent$LATITUDE)
sd(rent$LONGITUDE)
```



```{r,  fig.width=8, fig.height=8,fig.cap="Scatter plot for the train dataset",echo = FALSE}
train_num = train%>%dplyr::select(SCORE,CONFIRMED_STOREYS,CONFIRMED_UNITS,NO_OF_AREAS_EVALUATED, LATITUDE,LONGITUDE,Age_Evaluated)
plot(train_num)
```


**Table 1: Summary results of test and train dataset**

|  | Train Dataset|Test Dataset|
|--------------- |--------------- | --------------- | 
|**Built Year** |
|Mean/SD| 1961/18.46|1961/18.37|
|**Evaluated Year** |
|Mean/SD| 2018/1.47 | 2018/1.45|
|**Evaluated Age** |
|Mean/SD| 57.6/18.5 |57.9/18.4 |
|**Storeys** |
|Mean/SD| 7.6/6.1 |7.4/6.0|
|**Units** |
|Mean/SD| 88/94 |86/93 |
|**No of Evaluated Areas** |
|Mean/SD| 17.2/1.66 |17.1/1.67 |
|**Evaluated Score** |
|Mean/SD| 71.2/10 | 72.2/10 |
|**LATITUDE** |
|Mean/SD| 43.7/0.04 | 43.7/0.04 |
|**LONGITUDE** |
|Mean/SD| -79.4/0.09 |-79.4/0.09 |
|**Property type** |
|Private| 4014(84%) |4004(84%) |
|Housing| 289(6%)| 293(6%)|
|TCHC| 455(10%) |461(10%) |
|**Sample size** |4758 |4758|



## Process of Obtaining Final model
Firstly, I run the full regrssion model and the results are shown in the first column of Table 2. The variance inflation factor (VIF) are all less than 5, so no multicolinearity occurs. The LATITUDE is not significant and there are 7 predictors in the model, so I choose automated selection method by AIC and BIC measures, and the results are shown in column 2 and 3. The AIC model is the same as the full model, while the BIC model drops confirmed storeys, confirmed units and Latitude. The $R^2$ of BIC model is 0.078, only 0.2% smaller than the full model, and it has the smallest BIC measure. So I select the BIC model as my final model in the end. 


```{r}
full_model = lm(SCORE~Age_Evaluated+CONFIRMED_STOREYS+CONFIRMED_UNITS+NO_OF_AREAS_EVALUATED+as.factor(PROPERTY_TYPE)+ LATITUDE+LONGITUDE,data = train )
AIC_model = step(full_model)
n = nrow(train)
BIC_model = step(full_model,k = log(n))
```




```{r}
Test_BIC_model = lm(SCORE ~ Age_Evaluated + NO_OF_AREAS_EVALUATED + as.factor(PROPERTY_TYPE) + LONGITUDE, data = test)
```


```{r}
huxtable::huxreg(full_model,AIC_model,BIC_model,Test_BIC_model)
```

```{r}
library(regclass)
VIF(full_model)
```

## Goodness of Final model
From Figure 1, the additional conditions have been satisfied. The redisual plots for BIC model are shown in Figure2. The top-left figure shows that linearity and constant variance assumption are satisfied. The normal Q-Q plot shows the normality assumption is also hold. Then, the bottom two figures show that no obvious outliers and influntial points, but there are several leverage points. In all, all the assumptions are good, so we don't need to do further transformation. 

I validate the final model by the test dataset, and the results are shown in the last column of Table 2. The estimated coefficients between test dataset and train dataset have the similar sign and significance. But, we still find some difference, for example, the R2 of final model in train dataset is 7.8%, while the one in test dataset is 10.4%. The p-value of the coefficeint of age is less than 0.001, while it is between 0.01 and 0.05 in the test dataset. 


```{r,  fig.width=6, fig.height=6,fig.cap="Residual plots",echo = FALSE}
par(mfrow = c(2,2))
plot(BIC_model)
```

# Discussion

## Interpretation and importance 
From the previous analysis, we found that the satety score is related to the age, number of area evaluated, and their location. If one more age of the apartment, about 0.03 score decreases holding other variable constant. The (Toronto Community Hosing)TCHC building has the worst safety score than social housing and private housing, about 5 scores less than other types. However, the R-square is only 8%, this model can only explain 8% variation of the safety score. 

## Limitation of Analysis
Due to the low R-square of the final model, this model has limited prediction ability on the safety score. In order to increase the ability to explain the variation, we can add more variables into the model. 


\newpage

# Reference

RentSafeTO for Tenants. (2021, October 6). City of Toronto. https://www.toronto.ca/community-people/housing-shelter/rental-housing-tenant-information/rental-housing-standards/apartment-building-standards/rentsafeto-for-tenants/

Open Data Dataset. (2021,  October 22). City of Toronto Open Data Portal. https://open.toronto.ca/dataset/apartment-building-evaluation/


